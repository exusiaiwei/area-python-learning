We conduct a quantitative analysis contrasting human-written English news text with comparable large language model (LLM) output from 4 LLMs from the LLaMa family. Our analysis spans several measurable linguistic dimensions, including morphological, syntactic, psychometric and sociolinguistic aspects. The results reveal various measurable differences between human and AI-generated texts. Among others, human texts exhibit more scattered sentence length distributions, a distinct use of dependency and constituent types, shorter constituents, and more aggressive emotions (fear, disgust) than LLM-generated texts. LLM outputs use more numbers, symbols and auxiliaries (suggesting objective language) than human texts, as well as more pronouns. The sexist bias prevalent in human text is also expressed by LLMs. 1 Introduction Natural language generation (NLG) models (Radford et al.; Scao et al., 2022; Touvron et al., 2023) and instruction-tuned variants (OpenAI, 2023; Taori et al., 2023) output fluent, human-like text in many languages, English being the best represented. The extent to which these models truly understand semantics (Landgrebe and Smith, 2021; Søgaard, 2022), encode representations of the world (Li et al., 2022), generate fake statements (Kumar et al., 2023), or propagate specific moral and ethical values (Santurkar et al., 2023) is currently under active debate. Regardless, a crucial factor contributing to the persuasiveness of these models lies, in the very first place, in their exceptional linguistic fluency. A question that arises regards whether their storytelling strategies align with the linguistic patterns observed in human-generated texts. Do these models tend to use more flowery or redundant language? Do they exhibit preferences for specific Figure 1: We gather contemporary articles from the New York Times API and use their headlines as a prompt to produce LLaMa-generated news. We then compare both types of texts, measuring differences across aspects such as vocabulary, morphosyntactic structures, and semantic attributes. voices or syntactic structures in sentence generation? Are they prone to certain psychometric dimensions? However, contrasting such linguistic patterns is not trivial. Firstly, the creators of these models often insufficiently document the training data used. Even with available information, determining the extent of the training set’s influence on a sentence or whether it’s similar to an input sample remains challenging. Second, different domains exhibit distinct linguistic complexities, e.g., children textbooks differ from technical articles, and war articles may convey more anger compared to hotel reviews. Third, language is subject to societal influences, cultural norms, social factors, and geographic variations, which shape linguistic preferences and conventions. Thus, to contrast linguistic patterns between humans and machines, it is advisable to rely on a controlled environment. Yet, few efforts have been dedicated to measure differences, if any, in syntax, grammar, and other linguistic particularities between both types of texts.Contribution We study text generation models from the LLaMa (Touvron et al., 2023) family, and arXiv:2308.09067v1 [cs.CL] 17 Aug 2023 contrast several linguistic patterns against human text using English news text. To do so, we recover human-generated news and ask LLaMa models to generate news based on the headline and first words of the news. We query the New York Times API, retrieving news as they are published, to guarantee sterilization from the training set. We analyze various linguistic patterns such as: differences in the distribution of the vocabulary, sentence length, partof-speech (PoS) tags, differences in the distribution of syntactic structures, psychometric features such as the tone of the news articles and emotions detectable in the text, and sociolinguistic aspects like gender bias. We depict the overview in Figure 1. We also explore if these disparities change across models of different sizes. 2 Data preparation Next, we will delve into our data collection process for both human-generated and machine-generated content. 2.1 Data We generate the evaluation dataset relying on news published strictly after the release date of the models that we will use in this work. This strategy ensures that they do not have exposure to the news headlines and their content during pre-training. It is also in line with strategies proposed by other authors - such as Liu et al. (2023) - who take an equivalent angle to evaluate LLMs in the context of generative search engines. The reference humangenerated texts will be the news (lead paragraph) themselves. Crawling We use New York Times news, which are accessible through its API1. We retrieve the data based on their release dates, processing them in batches of 300 to avoid exceeding the API limit. The articles are retrieved in JSON format, and include relevant metadata such as the URL, section name, type of material, keywords, or publication date. Table 1 shows some information about the articles retrieved. Our main interest focuses on two specific fields: the headline and the lead paragraph. The lead paragraph serves as a concise summary of the primary information presented in the article. We discarded those articles that had an empty lead 1https://developer.nytimes.com/apis that we ac- cess through the pynytimes Python library (Den Heijer, 2022). Section  Category (%) Section name U.S. (15.81), World (11.85), Opinion (8.04), Arts (7.64), Business Day (6.92), New York (4.91), Sports (4.87), Books (3.71), Style (3.27), Movies (3.02), Crosswords & Games (2.58), Briefing (2.58), Food (1.96), Real State (1.84), Podcasts (1.61), Theater (1.58) Type of material News (70.62), Op-Ed (6.60), Review (5.18), Other (4.06), Interactive Feature (3.23), Briefing (2.86), Video (2.31), Obituary (2.30), Recipe (1.55), Letter (1.28) Document type Article (90.31), Multimedia (6.95), Recipe (1.55), Other (1.19) Table 1: Information about the articles used for this work. Each category shows the most frequent topics. paragraph. Particularly, we collected 11 133 articles from April 20 to July 13, 2023. The collected articles primarily consist of news pieces, although around 30% also include other types of texts, such as movie or book reviews. 2.2 Generation Let H = [h1, h2, ..., hN ] be a set of humangenerated texts, such that hi is a tuple of the form (ti, si) where ti is a headline and si is a paragraph of text with a summary of the corresponding news. Similarly, we will define M = [m1, m2, ..., mN ] as the set machine-generated news articles produced by a LLM such that mi is also a tuple of the from (t′i, s′i) where t′i = ti and s′i = [w′1, w′2, ..., w′ |si|] is a piece of synthetic text. For the generation of highquality text, language models aim to maximize the probability of the next word based on the previous content. To ensure that the models keep on track with the domain and topic, we initialize the previous content with the headline (the one chosen by the journalist that released the news) and the first three words of the human-generated lead paragraph to help the model start and follow the topic.2 For- mally, we first condition the model on c = t′i ·si[0:2] and every next word (i ≥ 3) will be predicted from a conditional distribution P (wi′|ci · s′ i[3:t−1]). LLaMa models (Touvron et al., 2023) To ap- proximate such distribution, we use pre-trained generative language models. We rely on all models from the LLaMA family: 7B, 13B, 30B and 65B. The range of versions enables us to study the impact of model size in our framework. Also, we focus on this family because it has been widely 2In preliminary experiments, certain LLM outputs encoun- tered difficulties in adhering to a minimal coherent structure when a minimum number of the body’s words were absent from the prompt.